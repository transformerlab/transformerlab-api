{
  "name": "OpenAI API Proxy Server",
  "uniqueId": "openai_api_proxy_server",
  "description": "A server that provides OpenAI-compatible RESTful APIs.",
  "plugin-format": "python",
  "type": "loader",
  "version": "1.0.11",
  "model_architectures": [
    "LlamaForCausalLM"
  ],
  "supported_hardware_architectures": ["cpu"],
  "files": ["main.py", "setup.sh"],
  "setup-script": "setup.sh",
  "parameters": {
    "max-model-len": {
      "title": "Maximum Model Length",
      "type": "integer"
    },
    "proxy-url": {
      "title": "Set Proxy URL",
      "type": "string",
      "default": "http://localhost:11434/v1/chat/completions"
    },
    "api-key": {
      "title": "Set API Key",
      "type": "string"
    }
  }
}
