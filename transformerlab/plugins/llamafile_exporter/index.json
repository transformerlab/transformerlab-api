{
  "name": "Llamafile Exporter",
  "uniqueId": "llamafile_exporter",
  "description": "Exports the current model to a fully contained self-executing llamafile.",
  "plugin-format": "python",
  "type": "exporter",
  "version": "0.1.4",
  "model_architectures": ["GGUF"],
  "supported_hardware_architectures": [
    "cpu",
    "cuda",
    "mlx"
  ],
  "export_architecture": "llamafile",
  "files": ["main.py", "setup.sh"],
  "setup-script": "setup.sh",
  "parameters": {
    "new_output_model_id": {
      "title": "Exported Model Name",
      "type": "string",
      "default": "my-exported-model"
    }
  }
}
