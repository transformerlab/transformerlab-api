[
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "1.0",
            "name": "Python Completion",
            "description": "Trains a SmolLM Base model to act as a python completion model"
        },
        "model": {
            "name": "HuggingFaceTB/SmolLM2-135M",
            "path": "HuggingFaceTB/SmolLM2-135M"
        },
        "datasets": {
            "name": "flytech/python-codes-25k",
            "path": "flytech/python-codes-25k"
        },
        "training": {
            "type": "LoRA",
            "plugin": "llama_trainer",
            "formatting_template": "{{output}}",
            "config_json": "{\"template_name\":\"ScaryHyena\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"HuggingFaceTB/SmolLM2-135M\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"{{output}}\\n\",\"dataset_name\":\"flytech/python-codes-25k\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate\":\"0.0005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"64\",\"lora_alpha\":\"128\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"python\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "name": "Dialogue Summarizing",
            "version": "1.0",
            "description": "Trains TinyLlama to summarize conversations."
        },
        "model": {
            "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
            "path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
        },
        "datasets": {
            "name": "samsum",
            "path": "samsum"
        },
        "training": {
            "type": "LoRA",
            "plugin": "llama_trainer",
            "formatting_template": "Instruction: Summarize the Following\nPrompt: {{dialogue}}\nGeneration: {{summary}}",
            "config_json": "{\"template_name\": \"Dialogue Summarizer\", \"plugin_name\": \"llama_trainer\", \"model_name\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", \"model_architecture\": \"LlamaForCausalLM\", \"formatting_template\": \"Instruction: Summarize the Following\\nPrompt: {{dialogue}}\\nGeneration: {{summary}}\", \"dataset_name\": \"samsum\", \"maximum_sequence_length\": \"2048\", \"batch_size\": \"4\", \"learning_rate\": \"0.00005\", \"num_train_epochs\": \"1\", \"max_steps\": \"-1\", \"lora_r\": \"32\", \"lora_alpha\": \"64\", \"lora_dropout\": \"0.05\", \"adaptor_name\": \"Summarizer\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "1.0",
            "name": "MachineLearningQnA",
            "description": "Trains a Qwen 2.5 model to answer machine learning questions"
        },
        "model": {
            "name": "Qwen/Qwen2.5-1.5B-Instruct",
            "path": "Qwen/Qwen2.5-1.5B-Instruct"
        },
        "datasets": {
            "name": "win-wang/Machine_Learning_QA_Collection",
            "path": "win-wang/Machine_Learning_QA_Collection"
        },
        "training": {
            "type": "LoRA",
            "plugin": "llama_trainer",
            "formatting_template": "{{text}}",
            "config_json": "{\"template_name\":\"MachineLearningQA\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"formatting_template\":\"{{text}}\\n\",\"dataset_name\":\"win-wang/Machine_Learning_QA_Collection\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"1\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"16\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.1\",\"adaptor_name\":\"ML-QA\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "1.0",
            "name": "MachineLearningQnA-MLX",
            "description": "Trains a Gemma 2 model to answer machine learning questions. Adapted from https://medium.com/tutorial-by-winston-wang/beginners-guide-to-fine-tuning-models-using-mlx-on-apple-silicon-1a21ebb70aed"
        },
        "model": {
            "name": "google/gemma-2-2b-it",
            "path": "google/gemma-2-2b-it"
        },
        "datasets": {
            "name": "Machine Learning QA Collection",
            "path": "win-wang/Machine_Learning_QA_Collection"
        },
        "training": {
            "type": "LoRA",
            "plugin": "mlx_lora_trainer",
            "formatting_template": "{{text}}",
            "config_json": "{\"template_name\":\"MachineLearningQnA\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"google/gemma-2-2b-it\",\"model_architecture\":\"Gemma2ForCausalLM\",\"formatting_template\":\"{{text}}\", \"dataset_name\":\"win-wang/Machine_Learning_QA_Collection\",\"lora_layers\":\"8\",\"batch_size\":\"4\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"8\",\"lora_alpha\":\"160\",\"iters\":\"200\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"50\",\"save_every\":\"50\",\"adaptor_name\":\"ml-qa\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "0.1",
            "name": "WikiSQL-MLX",
            "description": "Trains a model to answer SQL queries. Adapted from https://github.com/ml-explore/mlx-examples/"
        },
        "model": {
            "name": "meta-llama/Llama-3.2-1B",
            "path": "meta-llama/Llama-3.2-1B"
        },
        "datasets": {
            "name": "mlx-community/wikisql",
            "path": "mlx-community/wikisql"
        },
        "training": {
            "type": "LoRA",
            "plugin": "mlx_lora_trainer",
            "formatting_template": "Given the following description of an SQL table and its columns, provide the corresponding SQL to answer the question. {{text}}",
            "config_json": "{\"template_name\":\"WikiSQL\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"meta-llama/Llama-3.2-1B\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"Given the following description of an SQL table and its columns, provide the corresponding SQL to answer the question.\\n{{text}}\",\"dataset_name\":\"mlx-community/wikisql\",\"lora_layers\":\"8\",\"batch_size\":\"4\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"8\",\"lora_alpha\":\"160\",\"iters\":\"200\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"50\",\"save_every\":\"50\",\"adaptor_name\":\"ml-qa\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "name": "TouchRugby",
            "version": "1.0",
            "description": "Train an Llama 3.2 MLX model to answer questions about the rules of Touch Rugby."
        },
        "model": {
            "name": "mlx-community/Llama-3.2-1B-Instruct-4bit",
            "path": "mlx-community/Llama-3.2-1B-Instruct-4bit"
        },
        "datasets": {
            "name": "Trelis/touch-rugby-rules",
            "path": "Trelis/touch-rugby-rules"
        },
        "training": {
            "type": "LoRA",
            "plugin": "mlx_lora_trainer",
            "formatting_template": "{{prompt}}\n{{completion}}",
            "config_json": "{\"template_name\":\"TouchRugby\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"{{prompt}}\\n{{completion}}\",\"dataset_name\":\"Trelis/touch-rugby-rules\",\"lora_layers\":\"16\",\"batch_size\":\"8\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"32\",\"lora_alpha\":\"128\",\"iters\":\"120\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"20\",\"save_every\":\"10\",\"adaptor_name\":\"touch-rugby\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "name": "WikiSQL",
            "version": "1.0",
            "description": "Trains a model to answer SQL queries"
        },
        "model": {
            "name": "Qwen/Qwen2.5-1.5B-Instruct",
            "path": "Qwen/Qwen2.5-1.5B-Instruct"
        },
        "datasets": {
            "name": "mlx-community/wikisql",
            "path": "mlx-community/wikisql"
        },
        "training": {
            "type": "LoRA",
            "plugin": "llama_trainer",
            "formatting_template": "{{text}} ;",
            "config_json": "{\"template_name\":\"Wiki SQL\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"formatting_template\":\"{{text}} ;\",\"dataset_name\":\"mlx-community/wikisql\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"1\",\"learning_rate\":\"0.005\",\"num_train_epochs\":\"2\",\"max_steps\":\"-1\",\"lora_r\":\"32\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.1\",\"adaptor_name\":\"WikiSQL\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "1.1",
            "name": "Pirate Speech",
            "description": "Trains SmolLM to speak like a Pirate"
        },
        "model": {
            "name": "HuggingFaceTB/SmolLM-135M-Instruct",
            "path": "HuggingFaceTB/SmolLM-135M-Instruct"
        },
        "datasets": {
            "name": "Peyton3995/dolly-15k-mistral-pirate",
            "path": "Peyton3995/dolly-15k-mistral-pirate"
        },
        "training": {
            "type": "LoRA",
            "plugin": "llama_trainer",
            "formatting_template": "<instruction>\n{{instruction}}\n</instruction>\n<response>\n{{response}}\n</response>",
            "config_json": "{\"template_name\":\"Pirate Speech\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"HuggingFaceTB/SmolLM-135M-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"<instruction>\\n{{instruction}}\\n</instruction>\\n<response>\\n{{response}}\\n</response>\",\"dataset_name\":\"Peyton3995/dolly-15k-mistral-pirate\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate_schedule\":\"cosine\",\"learning_rate\":\"0.01\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"64\",\"lora_alpha\":\"128\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"Pirate_Speech\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "1.0",
            "name": "Instruct Tuning",
            "description": "Trains a SmolLM base model to be conversational, and use a specific instruct format(XML tags)"
        },
        "model": {
            "name": "HuggingFaceTB/SmolLM2-135M",
            "path": "HuggingFaceTB/SmolLM2-135M"
        },
        "datasets": {
            "name": "nickrosh/Evol-Instruct-Code-80k-v1",
            "path": "nickrosh/Evol-Instruct-Code-80k-v1"
        },
        "training": {
            "type": "LoRA",
            "plugin": "llama_trainer",
            "formatting_template": "<User>\n{{instruction}}\n</User>\n<Assistant>\n{{output}}\n</Assistant>\n",
            "config_json": "{\"template_name\":\"InstructTuning\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"HuggingFaceTB/SmolLM2-135M\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"<User>\\n{{instruction}}\\n</User>\\n<Assistant>\\n{{output}}\\n</Assistant>\\n\",\"dataset_name\":\"nickrosh/Evol-Instruct-Code-80k-v1\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate\":\"0.00003\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"4\",\"lora_alpha\":\"16\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"instruct\"}"
        },
        "test": {}
    }
]